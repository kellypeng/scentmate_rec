{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from pymongo import MongoClient\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def short_comments_df(short_ratings_df):\n",
    "    '''Takes in short_ratings dataframe, group by perfume id, return a dictionary\n",
    "    with perfume id as key, all short comments of that perfume as values\n",
    "\n",
    "    Parameter:\n",
    "    ---------\n",
    "    short ratings dataframe. Including perfume_id, rated_user_id, comments, url\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    dataframe, perfume_id as index, perfume short comments as another column\n",
    "    '''\n",
    "    scomments = defaultdict(list)\n",
    "    for pid in short_ratings_df['perfume_id'].unique():\n",
    "        df = short_ratings_df[(short_ratings_df['perfume_id'] == pid)]\n",
    "        for c in df['short_comment']:\n",
    "            scomments[pid].append(c)\n",
    "    stacked = pd.DataFrame.from_dict(scomments, orient='index').stack().sum(level=0) # aggregate comments to perfume id\n",
    "    short_comments_df = pd.DataFrame(stacked).rename(columns={0:'short_comments'}) # convert from pd series to dataframe\n",
    "    return short_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_comments(short_comments_df, long_comments_df):\n",
    "    '''\n",
    "    Join short comments df and long comments df, combine comments of each perfume id\n",
    "    to a document.\n",
    "\n",
    "    Parameter:\n",
    "    ---------\n",
    "    short_comments_df, long_comments_df\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    joined df, two columns, perfume id and all comments\n",
    "    '''\n",
    "    long_comments_df.set_index('perfume_id', inplace=True)\n",
    "    long_comments_df['long_comments'] = long_comments_df['comments'].apply(','.join)\n",
    "    all_comments = pd.merge(short_comments_df, long_comments_df, how='left', left_index=True, right_index=True)\n",
    "    all_comments = all_comments.fillna('.')\n",
    "    all_comments['all_comments'] = all_comments['short_comments'] + all_comments['long_comments']\n",
    "    all_comments.drop(['comments', 'short_comments', 'long_comments', 'url'], axis=1, inplace=True)\n",
    "    all_comments = all_comments.reset_index().rename(columns={'index':'perfume_id'})\n",
    "    return all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://fragrance:fragrance@35.164.86.3:27017/fragrance\")\n",
    "db = client.fragrance\n",
    "short_ratings = db.short_ratings\n",
    "short_ratings = pd.DataFrame(list(short_ratings.find({}, {'_id': 0})))\n",
    "perfume_comments = db.perfume_comments\n",
    "long_comments = pd.DataFrame(list(perfume_comments.find({}, {'_id': 0})))\n",
    "client.close()\n",
    "# Data preprocessing\n",
    "short_comments_df = short_comments_df(short_ratings)\n",
    "all_comments_df = combine_comments(short_comments_df, long_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process data for TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus(df):\n",
    "    '''Build corpus from dataframe'''\n",
    "    corpus = []\n",
    "    for doc in df['all_comments']:\n",
    "        corpus.append(doc)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_to_words(corpus):\n",
    "    '''Use jieba to split Chinese text return a list string of words'''\n",
    "    seg_list = []\n",
    "    for doc in corpus:\n",
    "        words = jieba.cut(doc)\n",
    "        string = \" \".join(words)\n",
    "        seg_list.append(string)\n",
    "    return seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_perfume_stopwords():\n",
    "    '''Get stopwords file customized for perfume reviews, return a list of words'''\n",
    "    with io.open('../models/perfume_cn_stopwords.txt', 'r', encoding='utf8') as f:\n",
    "        stpwdlst = f.read().split()\n",
    "    return stpwdlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vectorized_mat(seg_list, use_tfidf, stop_words, max_features=1000):\n",
    "    '''Get TFIDF or TF matrix from tokenized documents corpus\n",
    "    If use_tfidf is True --> TFIDF Vectorizer\n",
    "    If user_tfidf is False --> Count Vectorizer'''\n",
    "    Vectorizer = TfidfVectorizer if use_tfidf else CountVectorizer\n",
    "    vectorizer_model = Vectorizer(stop_words=stop_words,\n",
    "                           analyzer='word',\n",
    "                           max_features=max_features)\n",
    "    vec_docs = vectorizer_model.fit_transform(seg_list) # return a sparse matrix\n",
    "    return vectorizer_model, vec_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using NMF and LDA in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    '''Display topics generated from NMF and LDA mdoel'''\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize corpus\n",
    "stpwdlst = get_perfume_stopwords()\n",
    "corpus = get_corpus(all_comments_df)\n",
    "seg_list = split_to_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NMF is able to use tf-idf, thus fit documents to TFIDF\n",
    "tfidf_vectorizer, tfidf_docs = get_vectorized_mat(seg_list,\n",
    "                                                  use_tfidf=True,\n",
    "                                                  stop_words=stpwdlst,\n",
    "                                                  max_features=1000)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model, thus fit to CountVectorizer\n",
    "countvectorizer, tf_docs = get_vectorized_mat(seg_list,\n",
    "                                              use_tfidf=False,\n",
    "                                              stop_words=stpwdlst,\n",
    "                                              max_features=1000)\n",
    "tf_feature_names = countvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_topics = 12\n",
    "no_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found by NMF: \n",
      "Topic 0:\n",
      "木质 广藿香 香根草 辛辣 气息 胡椒 琥珀 男香 焚香 雪松 檀香 东方 麝香 烟草 温暖 树脂 鸢尾 干燥 香气 肉桂\n",
      "Topic 1:\n",
      "玫瑰 玫瑰花 牡丹 沉香 荔枝 广藿香 温柔 乌木 红玫瑰 胡椒 丝带 留香 麝香 精油 藏红花 白玫瑰 花瓣 馥郁 柏林 chloe\n",
      "Topic 2:\n",
      "香草 美食 琥珀 巧克力 杏仁 焦糖 奶油 温暖 广藿香 性感 甜腻 甜甜的 檀香 东方 蛋糕 牛奶 甜味 脂粉 浓郁 香甜\n",
      "Topic 3:\n",
      "花香 温柔 少女 脂粉 香味 甜美 女人 果香 麝香 特别 花果 香气 优雅 成熟 浓郁 甜甜的 好闻 水果 气息 花香调\n",
      "Topic 4:\n",
      "茉莉 茉莉花 橙花 白花 吲哚 铃兰 依兰 白色 茶香 麝香 浓郁 皂感 琥珀 中国 百合 清香 香气 柔和 茶叶 花香\n",
      "Topic 5:\n",
      "皮革 烟草 烟熏 动物 气息 乌木 男人 沉香 树脂 藏红花 男性 鸢尾 巴黎 茶香 李子 甜度 质感 鼠尾草 鸢尾花 不错\n",
      "Topic 6:\n",
      "柠檬 柑橘 橘子 橙花 清爽 薄荷 古龙水 马鞭草 橙子 罗勒 干净 生姜 皂感 青柠 古龙 简单 清新 茶香 柚子 绿茶\n",
      "Topic 7:\n",
      "薰衣草 男香 咖啡 鼠尾草 男士 绅士 海利 辛辣 雪松 豆蔻 柠檬 香调 气息 男人 馥奇 精油 杏仁 薄荷 少年 皂感\n",
      "Topic 8:\n",
      "小样 冬日 女性化 成熟 藏红花 中规中矩 迷恋 用过 正装 舒服 香气 重口 浓郁 无感 圆润 失望 第一支 无花果 特别 肥皂水\n",
      "Topic 9:\n",
      "清新 夏天 水生 海洋 干净 清爽 绿叶 黄瓜 好闻 西瓜 男香 青草 薄荷 海水 淡淡的 莲花 夏日 雏菊 清淡 海风\n",
      "Topic 10:\n",
      "晚香玉 栀子花 白花 栀子 椰子 花香 青绿 依兰 老香 馥郁 浓郁 橙花 质感 女人 吲哚 百合 大气 年代 白色 华丽\n",
      "Topic 11:\n",
      "留香 时间 香味 好闻 不错 持久 扩散 特别 夏天 舒服 冬天 很长 清淡 男香 太短 甜甜的 衣服 浓郁 推荐 超级\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics found by NMF: \")\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = nmf.fit_transform(tfidf_docs)\n",
    "H = nmf.components_\n",
    "print 'reconstruction error:', nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found by LDA: \n",
      "Topic 0:\n",
      "香草 紫罗兰 广藿香 杏仁 巧克力 美食 兰花 红毒 奶油 咖啡 粉末 天使 质感 午夜 整体 甜味 柔滑 蛋糕 组合 甜美\n",
      "Topic 1:\n",
      "花香 温柔 女人 留香 香味 茉莉 优雅 脂粉 特别 好闻 浓郁 成熟 晚香玉 麝香 清新 不错 白花 栀子花 性感 气息\n",
      "Topic 2:\n",
      "柑橘 柠檬 橘子 橙花 琥珀 留香 清新 娇兰 橙子 花香 香味 香草 经典 罗勒 老香 东方 温暖 辛辣 混合 香气\n",
      "Topic 3:\n",
      "茉莉 桂花 绿茶 百合 白花 茶香 花香 清新 香气 茶叶 红茶 气息 香味 茉莉花 橙花 留香 茶味 中国 名字 淡雅\n",
      "Topic 4:\n",
      "少女 果香 甜美 清新 花果 水果 留香 甜甜的 酸甜 桃子 荔枝 可爱 好闻 醋栗 清甜 活泼 甜蜜 时间 酸酸甜甜 香味\n",
      "Topic 5:\n",
      "清新 留香 柠檬 夏天 薄荷 干净 好闻 水生 柑橘 清爽 香味 特别 时间 不错 淡淡的 温柔 花香 麝香 舒服 气息\n",
      "Topic 6:\n",
      "玫瑰 红玫瑰 沉香 白玫瑰 少女 广藿香 乌木 香气 温柔 玫瑰花 留香 牡丹 荔枝 清新 香味 气息 柏林 胡椒 陛下 木质\n",
      "Topic 7:\n",
      "木质 薰衣草 皮革 男香 香根草 辛辣 胡椒 烟草 温暖 男人 气息 留香 香味 好闻 大地 男士 雪松 特别 不错 温柔\n",
      "Topic 8:\n",
      "气息 木质 花香 麝香 鸢尾 焚香 香气 名字 东方 树脂 整体 干燥 香料 粉感 香辛 辛辣 感受 柔和 动物 卤蛋\n",
      "Topic 9:\n",
      "香味 檀香 美食 甜腻 留香 温暖 蜂蜜 甜味 甜甜的 甜香 浓郁 水果 焦糖 香草 奶香 冬天 奶油 特别 木质 牛奶\n",
      "Topic 10:\n",
      "无花果 清新 花园 青草 气息 花香 绿叶 绿色 绿意 植物 香气 阳光 青绿 留香 地中海 海盐 铃兰 香味 夏天 椰子\n",
      "Topic 11:\n",
      "香奈儿 邂逅 小姐 五号 迪奥 香精 甜心 可可 经典 广藿香 街香 花香 花露水 清新 商业 留香 年轻 好闻 新版 广告\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics found by LDA: \")\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_left = lda.fit_transform(tf_docs)\n",
    "# lda_right = lda.components_\n",
    "# lda_right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually label 12 topics generatd from LDA\n",
    "topic_dict = {0: (u'甜美', u'甜蜜', u'甜味', u'美食', u'香草', u'柔滑'),\n",
    "              1: (u'温柔', u'优雅', u'成熟', u'女人', u'脂粉', u'性感'),\n",
    "              2: (u'清新', u'柑橘', u'经典', u'琥珀', u'老香', u'东方调'),\n",
    "              3: (u'白花系', u'清新', u'淡雅', u'茶香', u'平易近人', u'邻家女孩'),\n",
    "              4: (u'少女', u'果香', u'甜美', u'可爱', u'活泼', u'甜蜜'),\n",
    "              5: (u'清新', u'干净', u'夏天', u'清爽', u'舒服', u'清凉'),\n",
    "              6: (u'玫瑰', u'温柔', u'少女', u'牡丹', u'女人味', u'清新'),\n",
    "              7: (u'辛辣', u'温暖', u'男人味', u'温柔', u'稳重', u'成熟'),\n",
    "              8: (u'东方调', u'焚香', u'神秘', u'辛辣', u'深沉', u'柔和'),\n",
    "              9: (u'美食', u'甜蜜', u'温暖', u'甜味', u'浓郁', u'冬天'),\n",
    "              10: (u'无花果', u'清新', u'青草', u'绿叶调', u'植物', u'夏天'),\n",
    "              11: (u'经典', u'大牌', u'奢华', u'广为人知', u'商业香', u'广告多见')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_kw_dict = {}\n",
    "for idx, item in enumerate(lda_left):\n",
    "    perfume_kw_dict[idx] = topic_dict[np.argmax(item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert dictionary to dataframe for join convenience\n",
    "perfume_topic_df = pd.DataFrame.from_dict(perfume_kw_dict, orient='index')\n",
    "perfume_topic_df = perfume_topic_df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords_matrix = pd.get_dummies(perfume_topic_df.apply(pd.Series).stack()).sum(level=0).rename(columns = lambda x: 'keywords_' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_keywords_df = all_comments_df.join(keywords_matrix)\n",
    "perfume_keywords_df.drop('all_comments', axis=1, inplace=True)\n",
    "perfume_keywords_df.set_index('perfume_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_keywords_df.to_csv('../data/perfume_keywords_matrix.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using LDA Model in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_clean = [doc.split() for doc in seg_list]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index.\n",
    "dictionary = corpora.Dictionary(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(ldamodel.print_topics(num_topics=10, num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It seems that LDA gives better topics, go with LDA with 12 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hand_label_topics(H, vocabulary):\n",
    "    '''\n",
    "    Print the most influential words of each latent topic, and prompt the user\n",
    "    to label each topic. The user should use their humanness to figure out what\n",
    "    each latent topic is capturing.\n",
    "    '''\n",
    "    hand_labels = []\n",
    "    for i, row in enumerate(H):\n",
    "        top_five = np.argsort(row)[::-1][:20]\n",
    "        print 'topic', i\n",
    "        print '-->', ' '.join(vocabulary[top_five])\n",
    "        label = raw_input('please label this topic: ')\n",
    "        hand_labels.append(label)\n",
    "        print\n",
    "    return hand_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = np.array(tfidf_feature_names)\n",
    "hand_labels = hand_label_topics(H, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "for i, topic in enumerate(hand_labels):\n",
    "    topic_dict[i] = topic.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_topic = {}\n",
    "for i, row in enumerate(W):\n",
    "    perfume_topic[i] = topic_dict[np.argsort(row)[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert dictionary to dataframe for join convenience\n",
    "perfume_topic_df = pd.DataFrame.from_dict(perfume_topic, orient='index')\n",
    "# change coumn name in perfume_topic_df\n",
    "perfume_topic_df.rename(columns={0:'keywords'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords_df = raw_df.join(perfume_topic_df, how='left')\n",
    "keywords_df.drop(['url'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
